{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/atsu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import src.proc_data as procd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer_stem_nostop(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2),\n",
    "                        preprocessor=procd.parse_html,\n",
    "                        tokenizer=tokenizer_stem_nostop,\n",
    "                        max_features=512)\n",
    "tfidf = tfidf.fit(df['Page content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocabularies with smallest idf scores]\n",
      "abl: 1.12\n",
      "access: 1.16\n",
      "accord: 1.25\n",
      "account: 1.51\n",
      "across: 1.53\n",
      "action: 1.61\n",
      "activ: 1.63\n",
      "actual: 1.65\n",
      "ad: 1.74\n",
      "add: 1.77\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "# get idf score of vocabularies\n",
    "idf = tfidf.idf_\n",
    "print('[vocabularies with smallest idf scores]')\n",
    "sorted_idx = idf.argsort()\n",
    "for i in range(top):\n",
    "    print('%s: %.2f' %(tfidf.get_feature_names()[i], idf[sorted_idx[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_stream(path, size):\n",
    "    for chunk in pd.read_csv(path, chunksize=size):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000/27643] 0.513\n",
      "[4000/27643] 0.553\n",
      "[6000/27643] 0.5155\n",
      "[8000/27643] 0.5135\n",
      "[10000/27643] 0.525\n",
      "[12000/27643] 0.522\n",
      "[14000/27643] 0.5255\n",
      "[16000/27643] 0.5145\n",
      "[18000/27643] 0.502\n",
      "[20000/27643] 0.502\n",
      "[22000/27643] 0.516\n",
      "[24000/27643] 0.5075\n",
      "[26000/27643] 0.499\n",
      "[28000/27643] 0.49421789409616557\n",
      "bestscore(C=0.010000): 0.494218\n",
      "[2000/27643] 0.616\n",
      "[4000/27643] 0.5335\n",
      "[6000/27643] 0.535\n",
      "[8000/27643] 0.534\n",
      "[10000/27643] 0.5255\n",
      "[12000/27643] 0.5165\n",
      "[14000/27643] 0.5095\n",
      "[16000/27643] 0.5115\n",
      "[18000/27643] 0.512\n",
      "[20000/27643] 0.5365\n",
      "[22000/27643] 0.5015\n",
      "[24000/27643] 0.5165\n",
      "[26000/27643] 0.5115\n",
      "[28000/27643] 0.516737674984784\n",
      "bestscore(C=0.100000): 0.516738\n",
      "[2000/27643] 0.6495\n",
      "[4000/27643] 0.6525\n",
      "[6000/27643] 0.6255\n",
      "[8000/27643] 0.6325\n",
      "[10000/27643] 0.625\n",
      "[12000/27643] 0.595\n",
      "[14000/27643] 0.6105\n",
      "[16000/27643] 0.598\n",
      "[18000/27643] 0.5825\n",
      "[20000/27643] 0.5915\n",
      "[22000/27643] 0.5825\n",
      "[24000/27643] 0.607\n",
      "[26000/27643] 0.569\n",
      "[28000/27643] 0.5727328058429701\n",
      "bestscore(C=1.000000): 0.572733\n",
      "[2000/27643] 0.6495\n",
      "[4000/27643] 0.674\n",
      "[6000/27643] 0.648\n",
      "[8000/27643] 0.6515\n",
      "[10000/27643] 0.631\n",
      "[12000/27643] 0.6435\n",
      "[14000/27643] 0.644\n",
      "[16000/27643] 0.632\n",
      "[18000/27643] 0.634\n",
      "[20000/27643] 0.615\n",
      "[22000/27643] 0.6175\n",
      "[24000/27643] 0.635\n",
      "[26000/27643] 0.5895\n",
      "[28000/27643] 0.6062081558125381\n",
      "bestscore(C=3.000000): 0.606208\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2000\n",
    "\n",
    "classes = np.array([-1, 1])\n",
    "iters = int((27643+batch_size-1)/(batch_size))\n",
    "Cs = [0.01, 0.1, 1.0, 3.0]\n",
    "\n",
    "best_score = 0\n",
    "candidates = []\n",
    "\n",
    "\n",
    "\n",
    "for C in Cs:\n",
    "    alpha = 1 / (C * batch_size)\n",
    "    clf = SGDClassifier(loss='hinge', alpha=alpha)\n",
    "    stream = get_stream(path='train.csv', size=batch_size)\n",
    "    for i in range(iters):\n",
    "        batch = next(stream)\n",
    "        X_train, y_train = batch['Page content'], batch['Popularity']\n",
    "        if X_train is None:\n",
    "            break\n",
    "        X_train = tfidf.transform(X_train)\n",
    "        clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    \n",
    "        score = clf.score(X_train, y_train)\n",
    "        print('[{}/{}] {}'.format((i+1)*(batch_size), 27643, score))\n",
    "    \n",
    "    if score > best_score:\n",
    "        print('bestscore(C=%f): %f' %(C, score))\n",
    "        best_score = score\n",
    "        candidates.append({'clf' : clf, 'C' : C, 'score' : score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "X_test = tfidf.transform(df_test['Page content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cand in candidates:\n",
    "    predict = cand['clf'].predict(X_test)\n",
    "    output = np.zeros((X_test.shape[0], 2), dtype=int)\n",
    "    output[:, 0] = df_test['Id']\n",
    "    output[:, 1] = predict\n",
    "    df_output = pd.DataFrame(data=output, columns=['Id', 'Popularity'])\n",
    "    df_output.to_csv('test%f.csv' % (cand['C']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ML_ENV]",
   "language": "python",
   "name": "conda-env-ML_ENV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
